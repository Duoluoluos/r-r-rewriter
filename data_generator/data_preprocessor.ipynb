{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRT Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are teaching assistant for Machine Learning. You should help to user to answer on his question.\"}, {\"role\": \"user\", \"content\": \"What is machine learning?\"}, {\"role\": \"assistant\", \"content\": \"'Tis but the art of teaching machines to think, to learn from data most fine, and decisions to link.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are teaching assistant for Machine Learning. You should help to user to answer on his question.\"}, {\"role\": \"user\", \"content\": \"How doth neural networks work?\"}, {\"role\": \"assistant\", \"content\": \"They're like the brains of yon digital beast, with layers many, and nodes that cease.\"}]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "def convert_data_format(file_path, mode):\n",
    "    '''\n",
    "    Extract document and metadata from iaq json files\n",
    "    '''\n",
    "    if mode == '教材':\n",
    "        # Load the JSON data from the file\n",
    "        with open(file_path) as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract the 'parent' and 'text' values, merge them into 'knowledge', and add to the knowledge_list\n",
    "        meta_data = {}\n",
    "        meta_data['source'] = file_path.split('/')[-1].split('.')[0]\n",
    "        knowledge_list = [{\"messages\":[ {\"role\":\"system\", \"content\": f\"你很擅长处理保荐代表人考试的试题，我给你一个保荐代表人教材中的章节、考点，请你编写其对应的具体内容\\n。\"}, {\"role\":\"user\", \"content\":f\"请根据以下指定章节及考点：{item['parent']}，从该考点的子考点中选取一个进行详细的内容编写。\"} ,{\"role\": \"assistant\", \"content\": f\"{item['parent']} \\n{item['text']}\"}]} \n",
    "                            for item in data.values() if 'parent' in item.keys() and item['parent'] != '']\n",
    "        if '财务' in file_path:\n",
    "            meta_data['class'] = '财务'\n",
    "        elif '法规' in file_path:\n",
    "            meta_data['class'] = '法规'\n",
    "        return knowledge_list, meta_data\n",
    "    \n",
    "    elif mode == '例题':\n",
    "        with open(file_path) as file:\n",
    "            data = json.load(file)\n",
    "        meta_data = {}\n",
    "        meta_data['source'] = file_path.split('/')[-1].split('.')[0]\n",
    "        knowledge_list = []\n",
    "        knowledge_list.extend([ {\"text\": f\"章节：{meta_data['source']}\\n  题型：{item['instruction']}\\n 问题：{item['input']} \\n 答案：{item['output']} \\n 解析：{item['CoT']}\"}\n",
    "                                 for item in data.values() if 'instruction' in item.keys()  and 'input'  \n",
    "                                 in item.keys() and 'output'  in item.keys() and 'CoT'  in item.keys()]) \n",
    "        return knowledge_list, meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyllabusQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_file_path = '/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/data/dataset_split/train.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "first_row = df.iloc[1]\n",
    "# for column in df.columns:\n",
    "#     print(f\"{column}: {first_row[column]}\")\n",
    "print(first_row[\"question\"])\n",
    "print(first_row[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有txt文件的内容已成功保存到/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/texts.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 定义文件夹路径\n",
    "folder_path = '/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/syllabi/syllabi_redacted/text'\n",
    "\n",
    "# 初始化一个列表来存储所有文件的内容\n",
    "texts = []\n",
    "\n",
    "# 遍历文件夹中的所有文件\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        texts.append({\"text\": filename + content})\n",
    "\n",
    "# 将列表保存为JSON文件\n",
    "json_file_path = '/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/texts.json'\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(texts, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"所有txt文件的内容已成功保存到{json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FintextQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = '/home/wangqi/Projects/LLM_Examinee/data/FintextQA/fin_dataset_test.json'\n",
    "\n",
    "# Read the content of the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    content = json.load(file)\n",
    "\n",
    "text_list = []\n",
    "\n",
    "for item in content:\n",
    "    # Extract text from 'questions'\n",
    "    # if 'questions' in item and isinstance(item['questions'], list):\n",
    "    #     for question in item['questions']:\n",
    "    #         if 'question' in question:\n",
    "    #             text_list.append({\"text\" : question['question']})\n",
    "    if 'paragraphs' in item and isinstance(item['paragraphs'], list):\n",
    "        for paragraph in item['paragraphs']:\n",
    "            if 'text' in paragraph:\n",
    "                text_list.append({\"text\" :paragraph['text']})\n",
    "    if 'table' in item and isinstance(item['table']['table'], list):\n",
    "        merged_text = '\\n'.join(['\\t'.join(row) for row in item['table']['table']])\n",
    "        text_list.append({\"text\" : merged_text})\n",
    "\n",
    "json_file_path = '/home/wangqi/Projects/LLM_Examinee/data/FintextQA/texts.json'\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(text_list, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"所有json文件的内容已成功保存到{json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
