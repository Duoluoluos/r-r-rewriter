{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb0oHJ1Hm4cp"
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOFKOMJtnaeq"
   },
   "source": [
    "**Google Colab Only**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3WOvmwAnAsx"
   },
   "source": [
    "# Reference Generation/Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OW7cQ0jT21f"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# For Chinese users, changing your https/http proxy is necessary\n",
    "import os\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "from langchain.docstore.base import Docstore\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import ( # type: ignore\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrites Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SRCQA Rewrites Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CMDSiW3bExWK"
   },
   "outputs": [],
   "source": [
    "def get_data(file_path, mode):\n",
    "    '''\n",
    "    Extract document and metadata from iaq json files\n",
    "    '''\n",
    "    if mode == '教材':\n",
    "        # Load the JSON data from the file\n",
    "        with open(file_path) as file:\n",
    "            data = json.load(file)\n",
    "        # Extract the 'parent' and 'text' values, merge them into 'knowledge', and add to the knowledge_list\n",
    "        knowledge_list = []\n",
    "        for item in data.values():\n",
    "            parent_data = item['parent']\n",
    "            sub_block = item['sub_block']\n",
    "            sub_title = sub_block['title']\n",
    "            if sub_title == '经典例题详解':\n",
    "                continue\n",
    "            for key, value in sub_block.items():\n",
    "                if \"sub_block\" in key or \"mid_data\" in key:\n",
    "                    knowledge_list.extend([f\"{parent_data} : {sub_title} : {blocks['paragraph']}\" for blocks in sub_block[key] if 'paragraph' in blocks.keys()])\n",
    "        meta_data = {}\n",
    "        meta_data['source'] = file_path.split('/')[-1]\n",
    "        if '财务' in file_path:\n",
    "            meta_data['class'] = '财务'\n",
    "        elif '法规' in file_path:\n",
    "            meta_data['class'] = '法规'\n",
    "        return knowledge_list, meta_data\n",
    "    \n",
    "    elif mode == '例题':\n",
    "        with open(file_path) as file:\n",
    "            data = json.load(file)\n",
    "        meta_data = {}\n",
    "        meta_data['source'] = file_path.split('/')[-1].split('.')[0]\n",
    "        knowledge_list = []\n",
    "        knowledge_list.extend([{\"章节\":meta_data['source'],\"题型\":item['instruction'],\"问题\":item['input'],\"答案\":item['output'],\"解析\":item['CoT']}\n",
    "                                for item in data.values() if 'instruction' in item.keys()  and 'input'  \n",
    "                                in item.keys() and 'output' in item.keys() and 'CoT'  in item.keys()]) \n",
    "        return knowledge_list, meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document \n",
    "doc_folder = '/home/wangqi/Projects/LLM_Examinee/data/iaq_document/json_files/doc'\n",
    "title_doc = []\n",
    "knowledge_doc = []\n",
    "for f_file in os.listdir(doc_folder):    \n",
    "    file_path = os.path.join(doc_folder, f_file)\n",
    "    # load the json file\n",
    "    knowledge_list, meta_data = get_data(file_path, mode = '教材')\n",
    "    # construct langchain document\n",
    "    knowledge_doc.extend([ Document(page_content=knowledge) for knowledge in knowledge_list])\n",
    "knowledge_db = FAISS.from_documents(knowledge_doc, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load questions\n",
    "question_folder = '/home/wangqi/Projects/LLM_Examinee/data/iaq_document/json_files/test/mock'\n",
    "q_list = []\n",
    "for f_file in os.listdir(question_folder):    \n",
    "    file_path = os.path.join(question_folder, f_file)\n",
    "    # load the json file\n",
    "    q_list.extend(get_data(file_path, mode = '例题')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRT_Data_Aug(question, answer):\n",
    "    SRT_DA_instruction = \\\n",
    "    \"你学识渊博，请阅读这道保荐代表人考试试题，我提供了答案，首先请你一步一步地结合解析思考一下正确答案是如何得到的。\\\n",
    "    然后结合题目答案与解析复盘一下这道题目的考察要点。\\n\\\n",
    "    输出格式请遵循:\\\n",
    "    问题解析:.....\\n\\\n",
    "    考查要点:1. ......\\n2. .....\\n3. ......\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", SRT_DA_instruction),\n",
    "            (\"human\", \"试题如下：{question}\\n答案与解析如下：{answer}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(model_name = 'gpt-4o', temperature=0)\n",
    "    LI_chain = ( {\"question\": RunnablePassthrough(),\"answer\": RunnablePassthrough()} | prompt | llm | StrOutputParser())\n",
    "    return LI_chain.invoke({\"question\": question, \"answer\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for i in tqdm.tqdm(range(len(q_list))):\n",
    "    annotation = SRT_Data_Aug(q_list[i][\"问题\"],q_list[i][\"答案\"])\n",
    "    new_entry = {\"问题\": q_list[i][\"问题\"], \"考点\": annotation}\n",
    "    output_data.append(new_entry)\n",
    "    if i % 50 == 0:\n",
    "        print(new_entry)\n",
    "instruction = \"用户的查询是一道保荐代表人试题，你需要重写这道试题以便模型更好地检索。重写的方式将此题改写成题目的考察意图。\"\n",
    "lt_with_ins = []\n",
    "for item in output_data:\n",
    "    lt_with_ins.append({\"instruction\":instruction, \"input\":item[\"问题\"], \"output\":item[\"考点\"]})\n",
    "with open(\"data/SRCQA/SRC_SFT.json\", 'a', encoding='utf-8') as f:\n",
    "    json.dump(lt_with_ins, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_after_substring(s):\n",
    "    parts = s.split('考查要点:')\n",
    "    if len(parts) > 1:\n",
    "        return parts[1]\n",
    "    else:\n",
    "        return ''  # 如果子串不存在，返回空字符串\n",
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/SRCQA/SRC_SFT.json\", 'r', encoding='utf-8') as f:\n",
    "    SFT_json = json.load(f)\n",
    "    for i in range(len(SFT_json)):\n",
    "        SFT_json[i]['output'] = keep_after_substring(SFT_json[i]['output'])\n",
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/SRCQA/SRC_SFT_P.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(SFT_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SyllabusQA/FintexQA Rewrites Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA_Data_Aug(question, answer):\n",
    "    DA_instruction = \\\n",
    "    \"You are knowledgeable. Please read this question. I have provided the answer. First, please think about how the correct answer is obtained step by step in combination with the analysis. \\\n",
    "    Then, review the key points of this question in combination with the answer and analysis.\\n\\\n",
    "    Please follow the output format:\\\n",
    "    Problem Analysis:.....\\n\\\n",
    "    Key Points of Examination: 1. ......\\n2. .....\\n3. ......\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", DA_instruction),\n",
    "            (\"human\", \"The question is: {question}\\nThe answer is: {answer}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(model_name = 'gpt-4o', temperature=0)\n",
    "    LI_chain = ( {\"question\": RunnablePassthrough(),\"answer\": RunnablePassthrough()} | prompt | llm | StrOutputParser())\n",
    "    return LI_chain.invoke({\"question\": question, \"answer\": answer})\n",
    "\n",
    "def keep_after_substring(s):\n",
    "    parts = s.split('Key Points of Examination:')\n",
    "    if len(parts) > 1:\n",
    "        return parts[1]\n",
    "    else:\n",
    "        return ''  # 如果子串不存在，返回空字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyllabusQA Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['http_proxy'] = 'http://100.64.0.2:11080'\n",
    "os.environ['https_proxy'] = 'http://100.64.0.2:11080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  tqdm import tqdm\n",
    "exam_fn = '/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/data/dataset_split/train.csv'\n",
    "df = pd.read_csv(exam_fn)\n",
    "output_data = []\n",
    "for i in tqdm(range(1, len(df))):\n",
    "    sub_df = df.iloc[i]\n",
    "    query = sub_df['question']\n",
    "    ground_truth = sub_df['answer']\n",
    "    annotation = QA_Data_Aug(query, ground_truth)\n",
    "    new_entry = {\"question\": query, \"rewrites\": annotation}\n",
    "    output_data.append(new_entry)\n",
    "    if i % 50 == 0:\n",
    "        print(new_entry)\n",
    "instruction = \"The user's query is a question about Course Syllabi. You need to rewrite the user's query for better retrieval by the model. In the rewritten query, the user's intention of inquiry should be clarified.\"\n",
    "lt_with_ins = []\n",
    "for item in output_data:\n",
    "    lt_with_ins.append({\"instruction\":instruction, \"input\":item[\"question\"], \"output\":item[\"rewrites\"]})\n",
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/Syllabus_SFT.json\", 'a', encoding='utf-8') as f:\n",
    "    json.dump(lt_with_ins, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/Syllabus_SFT.json\", 'r', encoding='utf-8') as f:\n",
    "    SFT_json = json.load(f)\n",
    "    for i in range(len(SFT_json)):\n",
    "        SFT_json[i]['output'] = keep_after_substring(SFT_json[i]['output'])\n",
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/SyllabusQA/Syllabus_SFT_P.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(SFT_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FintextQA Rewrites Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "file_path = '/home/wangqi/Projects/r-r-rewriter/data/FintextQA/fin_dataset_train.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = json.load(file)\n",
    "output_data = []\n",
    "for item in tqdm(content):\n",
    "    new_entry = {}\n",
    "    if 'questions' in item and isinstance(item['questions'], list):\n",
    "        for sub_item in item['questions']:\n",
    "            question, answer = sub_item.get('question', ''), sub_item.get('answer', '')\n",
    "            if question and answer:\n",
    "                annotation = QA_Data_Aug(question, answer)\n",
    "                new_entry = {\"question\": question, \"answer\": answer, \"rewrites\": annotation}\n",
    "                output_data.append(new_entry)\n",
    "    else:\n",
    "        continue  # Skip items without 'questions' or not a list\n",
    "\n",
    "instruction = \"The user's query is a question about finance. You need to rewrite the user's query for better retrieval by the model. In the rewritten query, the user's intention of inquiry should be clarified.\"\n",
    "lt_with_ins = []\n",
    "for item in output_data:\n",
    "    lt_with_ins.append({\"instruction\":instruction, \"input\":item[\"question\"], \"output\":item[\"rewrites\"]})\n",
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/FintextQA/Fintext_SFT.json\", 'a', encoding='utf-8') as f:\n",
    "    json.dump(lt_with_ins, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/Fintext_SFT.json\", 'r', encoding='utf-8') as f:\n",
    "    SFT_json = json.load(f)\n",
    "    for i in range(len(SFT_json)):\n",
    "        SFT_json[i]['output'] = keep_after_substring(SFT_json[i]['output'])\n",
    "with open(\"/home/wangqi/Projects/r-r-rewriter/data/Fintext_SFT_P.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(SFT_json, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPia1QjweRTLX6UrtAsxhM+",
   "mount_file_id": "1bRNCOMRbcgrxg6okU51lSX8Ek97w-_aO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
