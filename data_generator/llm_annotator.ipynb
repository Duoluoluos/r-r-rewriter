{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb0oHJ1Hm4cp"
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOFKOMJtnaeq"
   },
   "source": [
    "**Google Colab Only**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3WOvmwAnAsx"
   },
   "source": [
    "# Reference Generation/Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OW7cQ0jT21f"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Chinese users, changing your https/http proxy is necessary\n",
    "import os\n",
    "os.environ[\"https_proxy\"] = \"100.64.0.2:11080\"\n",
    "os.environ[\"http_proxy\"] = \"100.64.0.2:11080\"\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "# Set work dir in Colab\n",
    "os.chdir(\"/home/wangqi/Projects/LLM_Examinee\")\n",
    "from langchain.docstore.base import Docstore\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import ( # type: ignore\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "import tqdm\n",
    "from data_generator.prompt_templates import SRT_instruction,SRT_few_shot_input,SRT_few_shot_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZux2Fp1UnxD"
   },
   "source": [
    "### Load SRT Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CMDSiW3bExWK"
   },
   "outputs": [],
   "source": [
    "def get_data(file_path, mode):\n",
    "    '''\n",
    "    Extract document and metadata from iaq json files\n",
    "    '''\n",
    "    if mode == '教材':\n",
    "        # Load the JSON data from the file\n",
    "        with open(file_path) as file:\n",
    "            data = json.load(file)\n",
    "        # Extract the 'parent' and 'text' values, merge them into 'knowledge', and add to the knowledge_list\n",
    "        knowledge_list = []\n",
    "        for item in data.values():\n",
    "            parent_data = item['parent']\n",
    "            sub_block = item['sub_block']\n",
    "            sub_title = sub_block['title']\n",
    "            if sub_title == '经典例题详解':\n",
    "                continue\n",
    "            for key, value in sub_block.items():\n",
    "                if \"sub_block\" in key or \"mid_data\" in key:\n",
    "                    knowledge_list.extend([f\"{parent_data} : {sub_title} : {blocks['paragraph']}\" for blocks in sub_block[key] if 'paragraph' in blocks.keys()])\n",
    "        meta_data = {}\n",
    "        meta_data['source'] = file_path.split('/')[-1]\n",
    "        if '财务' in file_path:\n",
    "            meta_data['class'] = '财务'\n",
    "        elif '法规' in file_path:\n",
    "            meta_data['class'] = '法规'\n",
    "        return knowledge_list, meta_data\n",
    "    \n",
    "    elif mode == '例题':\n",
    "        with open(file_path) as file:\n",
    "            data = json.load(file)\n",
    "        meta_data = {}\n",
    "        meta_data['source'] = file_path.split('/')[-1].split('.')[0]\n",
    "        knowledge_list = []\n",
    "        knowledge_list.extend([{\"章节\":meta_data['source'],\"题型\":item['instruction'],\"问题\":item['input'],\"答案\":item['output'],\"解析\":item['CoT']}\n",
    "                                for item in data.values() if 'instruction' in item.keys()  and 'input'  \n",
    "                                in item.keys() and 'output' in item.keys() and 'CoT'  in item.keys()]) \n",
    "        return knowledge_list, meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document \n",
    "doc_folder = '/home/wangqi/Projects/LLM_Examinee/database/iaq_document/json_files/doc'\n",
    "title_doc = []\n",
    "knowledge_doc = []\n",
    "for f_file in os.listdir(doc_folder):    \n",
    "    file_path = os.path.join(doc_folder, f_file)\n",
    "    # load the json file\n",
    "    knowledge_list, meta_data = get_data(file_path, mode = '教材')\n",
    "    # construct langchain document\n",
    "    knowledge_doc.extend([ Document(page_content=knowledge) for knowledge in knowledge_list])\n",
    "knowledge_db = FAISS.from_documents(knowledge_doc, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load questions\n",
    "question_folder = '/home/wangqi/Projects/LLM_Examinee/database/iaq_document/json_files/test/mock'\n",
    "q_list = []\n",
    "for f_file in os.listdir(question_folder):    \n",
    "    file_path = os.path.join(question_folder, f_file)\n",
    "    # load the json file\n",
    "    q_list.extend(get_data(file_path, mode = '例题')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_evaluator(question, answer, k, vector_db):\n",
    "    doc_candidates = vector_db.similarity_search(question)\n",
    "    if len(doc_candidates) > k:\n",
    "        doc_candidates = doc_candidates[:k]\n",
    "    res = []\n",
    "    for i in range(len(doc_candidates)):\n",
    "        prompt = f\"\"\"\n",
    "        Given the question, the answer with analysis, and the reference materials, please rate the reference materials based on their ability to support the solution to this question. The rating scale is from 0 to 5 points.\n",
    "\n",
    "        Scoring Criteria for Reference Materials:\n",
    "        - 1 point: The reference material is not related to the question.\n",
    "        - 2 points: The reference material is somewhat related but does not provide substantial support.\n",
    "        - 3 points: The reference material is related and provides some support for the answer.\n",
    "        - 4 points: The reference material is highly relevant and provides significant support for the answer.\n",
    "        - 5 points: The reference material is perfectly relevant and essential for understanding and solving the question.\n",
    "\n",
    "        Your response must be formatted as JSON, with the  \"ratings\" as the keys.\n",
    "\n",
    "        The question is as follows:\n",
    "        {question}\n",
    "\n",
    "        The answer and analysis are as follows:\n",
    "        {answer}\n",
    "\n",
    "        The reference materials are as follows:\n",
    "        {doc_candidates[i].page_content}\n",
    "        \"\"\"\n",
    "        llm = ChatOpenAI(model_name = 'gpt-4o-mini', temperature=0)\n",
    "        response = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "        res.append({\"reference\": doc_candidates[i].page_content, \"DPR_rank\": i, \"rating\": response})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrites Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRT_Data_Aug(question, answer):\n",
    "    SRT_DA_instruction = \\\n",
    "    \"你学识渊博，请阅读这道保荐代表人考试试题，我提供了答案，首先请你一步一步地结合解析思考一下正确答案是如何得到的。\\\n",
    "    然后结合题目答案与解析复盘一下这道题目的考察要点。\\n\\\n",
    "    输出格式请遵循:\\\n",
    "    问题解析:.....\\n\\\n",
    "    考查要点:1. ......\\n2. .....\\n3. ......\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", SRT_DA_instruction),\n",
    "            (\"human\", \"试题如下：{question}\\n答案与解析如下：{answer}\"),\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOpenAI(model_name = 'gpt-4o', temperature=0)\n",
    "    LI_chain = ( {\"question\": RunnablePassthrough(),\"answer\": RunnablePassthrough()} | prompt | llm | StrOutputParser())\n",
    "    return LI_chain.invoke({\"question\": question, \"answer\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for i in tqdm.tqdm(range(len(q_list))):\n",
    "    annotation = SRT_Data_Aug(q_list[i][\"问题\"],q_list[i][\"答案\"])\n",
    "    new_entry = {\"问题\": q_list[i][\"问题\"], \"考点\": annotation}\n",
    "    output_data.append(new_entry)\n",
    "    if i % 50 == 0:\n",
    "        print(new_entry)\n",
    "\n",
    "\n",
    "with open(\"database/iaq_document/annotation/SRC_LI.json\", 'a', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"用户的查询是一道保荐代表人试题，你需要重写这道试题以便模型更好地检索。重写的方式将此题改写成题目的考察意图。\"\n",
    "lt_with_ins = []\n",
    "for item in output_data:\n",
    "    lt_with_ins.append({\"instruction\":instruction, \"input\":item[\"问题\"], \"output\":item[\"考点\"]})\n",
    "with open(\"database/iaq_document/annotation/SRC_SFT.json\", 'a', encoding='utf-8') as f:\n",
    "    json.dump(lt_with_ins, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering LI with knowledge points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(entry_a, entry_b):\n",
    "    # 分词\n",
    "    set_a = set(entry_a.split())\n",
    "    set_b = set(entry_b.split())\n",
    "    \n",
    "    intersection = len(set_a.intersection(set_b))\n",
    "    union = len(set_a.union(set_b))\n",
    "    jaccard_sim = intersection / union\n",
    "    return jaccard_sim\n",
    "\n",
    "def is_match_jaccard(entry_a, entry_b, threshold=0.3):\n",
    "    jaccard_sim = jaccard_similarity(entry_a, entry_b)\n",
    "    return 1 if jaccard_sim >= threshold else 0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPia1QjweRTLX6UrtAsxhM+",
   "mount_file_id": "1bRNCOMRbcgrxg6okU51lSX8Ek97w-_aO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "iaq_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
